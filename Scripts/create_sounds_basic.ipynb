{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='../../chords_halves.wav'>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "c = AudioSegment.from_wav(\"../../C1.wav\")\n",
    "e = AudioSegment.from_wav(\"../../E1.wav\")\n",
    "g = AudioSegment.from_wav(\"../../G1.wav\")\n",
    "\n",
    "\n",
    "c = c[:500]\n",
    "e = e[:500]\n",
    "g = g[:500]\n",
    "\n",
    "\n",
    "third = c.overlay(e)\n",
    "\n",
    "chord = third.overlay(g)\n",
    "\n",
    "chords = chord * 60\n",
    "\n",
    "chords.export('../../chords_halves.wav', format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../GrandPiano.cmaj/e-2.wav', '../GrandPiano.cmaj/g1.wav', '../GrandPiano.cmaj/g0.wav', '../GrandPiano.cmaj/g-1.wav', '../GrandPiano.cmaj/e-1.wav', '../GrandPiano.cmaj/g2.wav', '../GrandPiano.cmaj/g-2.wav', '../GrandPiano.cmaj/c-2.wav', '../GrandPiano.cmaj/a-1.wav', '../GrandPiano.cmaj/f2.wav', '../GrandPiano.cmaj/f0.wav', '../GrandPiano.cmaj/c-1.wav', '../GrandPiano.cmaj/a-2.wav', '../GrandPiano.cmaj/f1.wav', '../GrandPiano.cmaj/d-1.wav', '../GrandPiano.cmaj/a2.wav', '../GrandPiano.cmaj/f-2.wav', '../GrandPiano.cmaj/d-2.wav', '../GrandPiano.cmaj/a1.wav', '../GrandPiano.cmaj/f-1.wav', '../GrandPiano.cmaj/a0.wav', '../GrandPiano.cmaj/b-1.wav', '../GrandPiano.cmaj/b-2.wav', '../GrandPiano.cmaj/c3.wav', '../GrandPiano.cmaj/c2.wav', '../GrandPiano.cmaj/c0.wav', '../GrandPiano.cmaj/c1.wav', '../GrandPiano.cmaj/b1.wav', '../GrandPiano.cmaj/b0.wav', '../GrandPiano.cmaj/b2.wav', '../GrandPiano.cmaj/e0.wav', '../GrandPiano.cmaj/e1.wav', '../GrandPiano.cmaj/e2.wav', '../GrandPiano.cmaj/d2.wav', '../GrandPiano.cmaj/d1.wav', '../GrandPiano.cmaj/d0.wav']\n"
     ]
    }
   ],
   "source": [
    "#glob the files corresponding to our Grand Piano library of notes\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "piano = glob.glob('../GrandPiano.cmaj/*.wav')\n",
    "\n",
    "print(piano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We must (at this point) define a dictionary mapping a range of color values to a set of playable notes\n",
    "\n",
    "#Our colors so far:\n",
    "# Red\n",
    "# Yellow\n",
    "# Green\n",
    "# Cyan\n",
    "# Blue\n",
    "# Magenta\n",
    "\n",
    "\n",
    "#'Color' attributes:\n",
    "# hue range\n",
    "# playable notes\n",
    "\n",
    "# value determines reverb, attack, release\n",
    "# saturation determines pace, steps (of 'arp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color():\n",
    "    def __init__(self, name, chords, hue_range):\n",
    "        self = self\n",
    "        self.name = name\n",
    "        self.chords = chords\n",
    "        self.hue_range = hue_range\n",
    "    def toString():\n",
    "        print(self.chords)\n",
    "        print(self.name)\n",
    "        print(self.hue_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there will be a bug someday relating to the boundary between colors\n",
    "\n",
    "red = color('red', {'c': ['c','d','e','b'], 'f': ['f','g','a','c','e']}, [[0, 50], [340,360]])\n",
    "green = color('green', {'g': ['g','b','d','a'], 'g2': ['g','b','d','g']}, [80, 160])\n",
    "yellow = color('yellow', {'sad': ['c','d','f','a'], 'f': ['f','a','c']}, [50, 80])\n",
    "cyan = color('cyan', {'c': ['c','e','g','b'], 'g': ['g','b','c','e']}, [160, 180])\n",
    "blue = color('blue', {'fear': ['e','a','c','e'], 'admiration': ['c','f','a','d']}, [180, 220])\n",
    "magenta = color('magenta', {'-d': ['-d','g','b'], 'e': ['e','g','b']}, [245, 340])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's store these colors in a global list\n",
    "\n",
    "colors = []\n",
    "colors.append(red)\n",
    "colors.append(green)\n",
    "colors.append(yellow)\n",
    "colors.append(cyan)\n",
    "colors.append(blue)\n",
    "colors.append(magenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_color(hue_value):\n",
    "    \"\"\"This function determines which sound mapping should be applied\n",
    "    to a specific mean hue value generated from an image.\"\"\"\n",
    "    \n",
    "    assigned_color = ''\n",
    "    \n",
    "    for color in colors:\n",
    "        \n",
    "        #because red has two ranges, need an edge case\n",
    "        if(color.name != 'red'):\n",
    "            \n",
    "            if(hue_value < color.hue_range[1] and hue_value > color.hue_range[0]):\n",
    "                assigned_color = color\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            #honestly assigned_color equals red if we get here...\n",
    "            \n",
    "            #because red has two ranges\n",
    "            for span in color.hue_range:\n",
    "                \n",
    "                if(hue_value < span[1] and hue_value > span[0]):\n",
    "                    assigned_color = color\n",
    "    \n",
    "    return assigned_color\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next: we have to choose the right Grand Piano notes to play back corresponding to the average hue\n",
    "#We first need to determine the trajectory of the piece.\n",
    "# how long will it be? is there an arc to the color/mood story?\n",
    "#but for now we'll just focus on our river clip\n",
    "\n",
    "#in any case, this requires a string comparison from our color.chords to the available matches\n",
    "#in the Grand Piano library of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define as function: assign_possible_notes\n",
    "\n",
    "#mock workflow based upon river footage\n",
    "assigned_color = assign_color(132.69)\n",
    "possible_notes = {}\n",
    "\n",
    "for chord in assigned_color.chords:\n",
    "    \n",
    "    #add dictionary key\n",
    "    possible_notes[chord] = []\n",
    "    \n",
    "    for comp in assigned_color.chords[chord]:\n",
    "\n",
    "        for note in piano:\n",
    "            \n",
    "            if note[19] == comp:\n",
    "                \n",
    "                #add notes as values for the chord key\n",
    "                possible_notes[chord].append(note)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'g': ['../GrandPiano.cmaj/g1.wav',\n",
       "  '../GrandPiano.cmaj/g0.wav',\n",
       "  '../GrandPiano.cmaj/g-1.wav',\n",
       "  '../GrandPiano.cmaj/g2.wav',\n",
       "  '../GrandPiano.cmaj/g-2.wav',\n",
       "  '../GrandPiano.cmaj/b-1.wav',\n",
       "  '../GrandPiano.cmaj/b-2.wav',\n",
       "  '../GrandPiano.cmaj/b1.wav',\n",
       "  '../GrandPiano.cmaj/b0.wav',\n",
       "  '../GrandPiano.cmaj/b2.wav',\n",
       "  '../GrandPiano.cmaj/d-1.wav',\n",
       "  '../GrandPiano.cmaj/d-2.wav',\n",
       "  '../GrandPiano.cmaj/d2.wav',\n",
       "  '../GrandPiano.cmaj/d1.wav',\n",
       "  '../GrandPiano.cmaj/d0.wav',\n",
       "  '../GrandPiano.cmaj/a-1.wav',\n",
       "  '../GrandPiano.cmaj/a-2.wav',\n",
       "  '../GrandPiano.cmaj/a2.wav',\n",
       "  '../GrandPiano.cmaj/a1.wav',\n",
       "  '../GrandPiano.cmaj/a0.wav'],\n",
       " 'g2': ['../GrandPiano.cmaj/g1.wav',\n",
       "  '../GrandPiano.cmaj/g0.wav',\n",
       "  '../GrandPiano.cmaj/g-1.wav',\n",
       "  '../GrandPiano.cmaj/g2.wav',\n",
       "  '../GrandPiano.cmaj/g-2.wav',\n",
       "  '../GrandPiano.cmaj/b-1.wav',\n",
       "  '../GrandPiano.cmaj/b-2.wav',\n",
       "  '../GrandPiano.cmaj/b1.wav',\n",
       "  '../GrandPiano.cmaj/b0.wav',\n",
       "  '../GrandPiano.cmaj/b2.wav',\n",
       "  '../GrandPiano.cmaj/d-1.wav',\n",
       "  '../GrandPiano.cmaj/d-2.wav',\n",
       "  '../GrandPiano.cmaj/d2.wav',\n",
       "  '../GrandPiano.cmaj/d1.wav',\n",
       "  '../GrandPiano.cmaj/d0.wav',\n",
       "  '../GrandPiano.cmaj/g1.wav',\n",
       "  '../GrandPiano.cmaj/g0.wav',\n",
       "  '../GrandPiano.cmaj/g-1.wav',\n",
       "  '../GrandPiano.cmaj/g2.wav',\n",
       "  '../GrandPiano.cmaj/g-2.wav']}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use value and hue information to choose a progression of notes\n",
    "#open question: how will the number of notes being played at once be determined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fund(possible_notes, value):\n",
    "    \"\"\"creates a score determined by the aesthetic quality of an image\"\"\"\n",
    "    \n",
    "    from pydub import AudioSegment\n",
    "    \n",
    "    \n",
    "    fund = []\n",
    "    \n",
    "    #happier image\n",
    "    if(value > .5):\n",
    "        \n",
    "        #define fundamental low chord\n",
    "        for note in possible_notes['g']:\n",
    "            \n",
    "            i = 0\n",
    "            if(note[-5] == \"0\"):\n",
    "                \n",
    "                aud = AudioSegment.from_wav(note)\n",
    "                aud = aud[:1000]\n",
    "                \n",
    "                fund.append(aud)\n",
    "\n",
    "    \n",
    "    #sadder image\n",
    "    else:\n",
    "    \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return fund\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fund(fundamentals, length):\n",
    "    \"\"\"writes an output file with the notes determined by the image\"\"\"\n",
    "    \n",
    "    temp = fundamentals[0]\n",
    "    \n",
    "    for i in range(1, len(fundamentals)):\n",
    "        temp = temp.overlay(fundamentals[i])\n",
    "    \n",
    "    temp = temp * length\n",
    "    \n",
    "    temp.export(\"../../programmed1.wav\", format = 'wav')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "fundamentals = assign_fund(possible_notes, .6)\n",
    "create_fund(fundamentals, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
