{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../C1.wav'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-eb43df6cad33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../C1.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../E1.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAudioSegment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../G1.wav\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/seniorproject-B-zkFwkL/lib/python3.6/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_wav\u001b[0;34m(cls, file, parameters)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_wav\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wav'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/seniorproject-B-zkFwkL/lib/python3.6/site-packages/pydub/audio_segment.py\u001b[0m in \u001b[0;36mfrom_file\u001b[0;34m(cls, file, format, codec, parameters, **kwargs)\u001b[0m\n\u001b[1;32m    620\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m         \u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclose_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_fd_or_path_or_tempfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtempfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mformat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/share/virtualenvs/seniorproject-B-zkFwkL/lib/python3.6/site-packages/pydub/utils.py\u001b[0m in \u001b[0;36m_fd_or_path_or_tempfile\u001b[0;34m(fd, mode, tempfile)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbasestring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m         \u001b[0mfd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m         \u001b[0mclose_fd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../C1.wav'"
     ]
    }
   ],
   "source": [
    "from pydub import AudioSegment\n",
    "\n",
    "\n",
    "c = AudioSegment.from_wav(\"../../C1.wav\")\n",
    "e = AudioSegment.from_wav(\"../../E1.wav\")\n",
    "g = AudioSegment.from_wav(\"../../G1.wav\")\n",
    "\n",
    "\n",
    "c = c[:500]\n",
    "e = e[:500]\n",
    "g = g[:500]\n",
    "\n",
    "\n",
    "third = c.overlay(e)\n",
    "\n",
    "chord = third.overlay(g)\n",
    "\n",
    "chords = chord * 60\n",
    "\n",
    "chords.export('../../chords_halves.wav', format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['../GrandPiano.cmaj/f5.wav', '../GrandPiano.cmaj/f4.wav', '../GrandPiano.cmaj/g2.wav', '../GrandPiano.cmaj/f6.wav', '../GrandPiano.cmaj/g3.wav', '../GrandPiano.cmaj/f3.wav', '../GrandPiano.cmaj/f2.wav', '../GrandPiano.cmaj/g6.wav', '../GrandPiano.cmaj/g4.wav', '../GrandPiano.cmaj/g5.wav', '../GrandPiano.cmaj/a2.wav', '../GrandPiano.cmaj/a3.wav', '../GrandPiano.cmaj/a1.wav', '../GrandPiano.cmaj/a4.wav', '../GrandPiano.cmaj/a5.wav', '../GrandPiano.cmaj/c3.wav', '../GrandPiano.cmaj/c2.wav', '../GrandPiano.cmaj/b4.wav', '../GrandPiano.cmaj/b5.wav', '../GrandPiano.cmaj/c5.wav', '../GrandPiano.cmaj/b1.wav', '../GrandPiano.cmaj/c4.wav', '../GrandPiano.cmaj/b2.wav', '../GrandPiano.cmaj/c6.wav', '../GrandPiano.cmaj/c7.wav', '../GrandPiano.cmaj/b3.wav', '../GrandPiano.cmaj/d4.wav', '../GrandPiano.cmaj/d5.wav', '../GrandPiano.cmaj/e3.wav', '../GrandPiano.cmaj/d6.wav', '../GrandPiano.cmaj/e2.wav', '../GrandPiano.cmaj/e6.wav', '../GrandPiano.cmaj/d2.wav', '../GrandPiano.cmaj/d3.wav', '../GrandPiano.cmaj/e5.wav', '../GrandPiano.cmaj/e4.wav']\n"
     ]
    }
   ],
   "source": [
    "#glob the files corresponding to our Grand Piano library of notes\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "piano = glob.glob('../GrandPiano.cmaj/*.wav') \n",
    "\n",
    "print(piano)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We must (at this point) define a dictionary mapping a range of color values to a set of playable notes\n",
    "\n",
    "#Our colors so far:\n",
    "# Red\n",
    "# Yellow\n",
    "# Green\n",
    "# Cyan\n",
    "# Blue\n",
    "# Magenta\n",
    "\n",
    "\n",
    "#'Color' attributes:\n",
    "# hue range\n",
    "# playable notes\n",
    "\n",
    "# value determines reverb, attack, release\n",
    "# saturation determines pace, steps (of 'arp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class color():\n",
    "    def __init__(self, name, chords, hue_range):\n",
    "        self = self\n",
    "        self.name = name\n",
    "        self.chords = chords\n",
    "        self.hue_range = hue_range\n",
    "    def toString():\n",
    "        print(self.chords)\n",
    "        print(self.name)\n",
    "        print(self.hue_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there will be a bug someday relating to the boundary between colors\n",
    "\n",
    "red = color('red', {'c': ['c','d','e','b'], 'f': ['f','g','a','c','e']}, [[0, 50], [340,360]])\n",
    "green = color('green', {'g': ['g','b','d','a'], 'g2': ['g','b','d','g']}, [80, 160])\n",
    "yellow = color('yellow', {'sad': ['c','d','f','a'], 'f': ['f','a','c']}, [50, 80])\n",
    "cyan = color('cyan', {'c': ['c','e','g','b'], 'g': ['g','b','c','e']}, [160, 180])\n",
    "blue = color('blue', {'fear': ['e','a','c','e'], 'admiration': ['c','f','a','d']}, [180, 220])\n",
    "magenta = color('magenta', {'-d': ['-d','g','b'], 'e': ['e','g','b']}, [245, 340])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's store these colors in a global list\n",
    "\n",
    "colors = []\n",
    "colors.append(red)\n",
    "colors.append(green)\n",
    "colors.append(yellow)\n",
    "colors.append(cyan)\n",
    "colors.append(blue)\n",
    "colors.append(magenta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_color(hue_value):\n",
    "    \"\"\"This function determines which sound mapping should be applied\n",
    "    to a specific mean hue value generated from an image.\"\"\"\n",
    "    \n",
    "    assigned_color = ''\n",
    "    \n",
    "    for color in colors:\n",
    "        \n",
    "        #because red has two ranges, need an edge case\n",
    "        if(color.name != 'red'):\n",
    "            \n",
    "            if(hue_value < color.hue_range[1] and hue_value > color.hue_range[0]):\n",
    "                assigned_color = color\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            #honestly assigned_color equals red if we get here...\n",
    "            \n",
    "            #because red has two ranges\n",
    "            for span in color.hue_range:\n",
    "                \n",
    "                if(hue_value < span[1] and hue_value > span[0]):\n",
    "                    assigned_color = color\n",
    "    \n",
    "    return assigned_color\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#next: we have to choose the right Grand Piano notes to play back corresponding to the average hue\n",
    "#We first need to determine the trajectory of the piece.\n",
    "# how long will it be? is there an arc to the color/mood story?\n",
    "#but for now we'll just focus on our river clip\n",
    "\n",
    "#in any case, this requires a string comparison from our color.chords to the available matches\n",
    "#in the Grand Piano library of notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define as function: assign_possible_notes\n",
    "\n",
    "#mock workflow based upon river footage\n",
    "#assigned_color = assign_color(132.69)\n",
    "\n",
    "def assign_possible_notes(color):\n",
    "    \"\"\"assigns possible notes for color\"\"\"\n",
    "    \n",
    "    possible_notes = {}\n",
    "\n",
    "    for chord in color.chords:\n",
    "\n",
    "        #add dictionary key\n",
    "        possible_notes[chord] = []\n",
    "\n",
    "        for comp in color.chords[chord]:\n",
    "\n",
    "            for note in piano:\n",
    "\n",
    "                if note[19] == comp:\n",
    "\n",
    "                    #add notes as values for the chord key\n",
    "                    possible_notes[chord].append(note)\n",
    "                    \n",
    "    return possible_notes\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../GrandPiano.cmaj/g2.wav',\n",
       " '../GrandPiano.cmaj/g3.wav',\n",
       " '../GrandPiano.cmaj/g6.wav',\n",
       " '../GrandPiano.cmaj/g4.wav',\n",
       " '../GrandPiano.cmaj/g5.wav',\n",
       " '../GrandPiano.cmaj/b4.wav',\n",
       " '../GrandPiano.cmaj/b5.wav',\n",
       " '../GrandPiano.cmaj/b1.wav',\n",
       " '../GrandPiano.cmaj/b2.wav',\n",
       " '../GrandPiano.cmaj/b3.wav',\n",
       " '../GrandPiano.cmaj/d4.wav',\n",
       " '../GrandPiano.cmaj/d5.wav',\n",
       " '../GrandPiano.cmaj/d6.wav',\n",
       " '../GrandPiano.cmaj/d2.wav',\n",
       " '../GrandPiano.cmaj/d3.wav',\n",
       " '../GrandPiano.cmaj/g2.wav',\n",
       " '../GrandPiano.cmaj/g3.wav',\n",
       " '../GrandPiano.cmaj/g6.wav',\n",
       " '../GrandPiano.cmaj/g4.wav',\n",
       " '../GrandPiano.cmaj/g5.wav']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_notes['g2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use value and hue information to choose a progression of notes\n",
    "#open question: how will the number of notes being played at once be determined?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_fund(possible_notes, value):\n",
    "    \"\"\"creates a score determined by the aesthetic quality of an image\"\"\"\n",
    "    \n",
    "    from pydub import AudioSegment\n",
    "    \n",
    "    \n",
    "    fund = []\n",
    "    \n",
    "    #happier image\n",
    "    if(value > .5):\n",
    "        \n",
    "        #define fundamental low chord\n",
    "        for note in possible_notes['g']:\n",
    "            \n",
    "            i = 0\n",
    "            if(note[-5] == \"2\"):\n",
    "                \n",
    "                aud = AudioSegment.from_wav(note)\n",
    "                aud = aud[:1000]\n",
    "                \n",
    "                fund.append(aud)\n",
    "\n",
    "    \n",
    "    #sadder image\n",
    "    else:\n",
    "    \n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    return fund\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_fund(fundamentals, length):\n",
    "    \"\"\"writes an output file with the notes determined by the image\"\"\"\n",
    "    \n",
    "    temp = fundamentals[0]\n",
    "    \n",
    "    for i in range(1, len(fundamentals)):\n",
    "        temp = temp.overlay(fundamentals[i])\n",
    "    \n",
    "    temp = temp * length\n",
    "    \n",
    "    temp.export(\"../../programmed1.wav\", format = 'wav')\n",
    "    \n",
    "    return temp\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_harm(possible_notes, value, saturation):\n",
    "    \"\"\"use the image to create a harmony to overlay on the fundamental chords\"\"\"\n",
    "    \n",
    "    import random\n",
    "    from pydub import AudioSegment\n",
    "    \n",
    "    notes = set()\n",
    "    \n",
    "    melody = []\n",
    "    \n",
    "    #now randomly select one of each note to add to the melody\n",
    "    random.shuffle(possible_notes['g'])\n",
    "    \n",
    "    len_mel = 0\n",
    "    \n",
    "    #this is hard coded at 'g' right now; try to determine with color\n",
    "    for note in possible_notes['g']:\n",
    "        \n",
    "        #upper octaves\n",
    "        if((note[-5] == \"4\" or note[-5] == \"5\")):\n",
    "            \n",
    "            \n",
    "            notes.add(note[-6])\n",
    "            if(len(notes) > len_mel):\n",
    "                da = AudioSegment.from_wav(note)\n",
    "                da = da[:500]\n",
    "                melody.append(da)\n",
    "            \n",
    "            len_mel = len(melody)\n",
    "            \n",
    "    return melody"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_harm(melody, saturation, value, length):\n",
    "    \"\"\"used to create the harmony\"\"\"\n",
    "    \n",
    "    import random\n",
    "    \n",
    "    temp1 = melody[0]\n",
    "    \n",
    "    for i in range(1, len(melody)):\n",
    "        temp1 = temp1 + melody[i]\n",
    "    \n",
    "    temp1 = temp1 * (length//2)\n",
    "    \n",
    "    random.shuffle(melody)\n",
    "    \n",
    "    temp2 = melody[0]\n",
    "    \n",
    "    for i in range(1,len(melody)):\n",
    "        temp2 = temp2 + melody[i]\n",
    "    \n",
    "    temp2 = temp2 * (length//2)\n",
    "    \n",
    "    mel = temp1 + temp2\n",
    "    \n",
    "    mel.export(\"../../mel.wav\", format = 'wav')\n",
    "    \n",
    "    return mel\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_score(fundamental, melody):\n",
    "    \"\"\"creates the completed score for one section of footage\"\"\"\n",
    "    \n",
    "    #chord intro\n",
    "    intro = fundamental[:5000]\n",
    "    \n",
    "    #add mel1\n",
    "    build1 = fundamental[:7500].overlay(melody[:7500])\n",
    "    \n",
    "    #build to shift\n",
    "    tension = melody[7500:10000]\n",
    "    \n",
    "    #shift\n",
    "    chorus2 = fundamental[:10000].overlay(melody[20000:30000])\n",
    "    \n",
    "    glue1 = intro + build1\n",
    "    glue2 = glue1 + tension\n",
    "    glue3 = glue2 + chorus2\n",
    "    \n",
    "    #fade_score = glue3.fade_in(1000).fade_out(5000)\n",
    "    \n",
    "    glue3.export(\"../../score1.wav\", format = 'wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'g': ['../GrandPiano.cmaj/g2.wav', '../GrandPiano.cmaj/g3.wav', '../GrandPiano.cmaj/g6.wav', '../GrandPiano.cmaj/g4.wav', '../GrandPiano.cmaj/g5.wav', '../GrandPiano.cmaj/b4.wav', '../GrandPiano.cmaj/b5.wav', '../GrandPiano.cmaj/b1.wav', '../GrandPiano.cmaj/b2.wav', '../GrandPiano.cmaj/b3.wav', '../GrandPiano.cmaj/d4.wav', '../GrandPiano.cmaj/d5.wav', '../GrandPiano.cmaj/d6.wav', '../GrandPiano.cmaj/d2.wav', '../GrandPiano.cmaj/d3.wav', '../GrandPiano.cmaj/a2.wav', '../GrandPiano.cmaj/a3.wav', '../GrandPiano.cmaj/a1.wav', '../GrandPiano.cmaj/a4.wav', '../GrandPiano.cmaj/a5.wav'], 'g2': ['../GrandPiano.cmaj/g2.wav', '../GrandPiano.cmaj/g3.wav', '../GrandPiano.cmaj/g6.wav', '../GrandPiano.cmaj/g4.wav', '../GrandPiano.cmaj/g5.wav', '../GrandPiano.cmaj/b4.wav', '../GrandPiano.cmaj/b5.wav', '../GrandPiano.cmaj/b1.wav', '../GrandPiano.cmaj/b2.wav', '../GrandPiano.cmaj/b3.wav', '../GrandPiano.cmaj/d4.wav', '../GrandPiano.cmaj/d5.wav', '../GrandPiano.cmaj/d6.wav', '../GrandPiano.cmaj/d2.wav', '../GrandPiano.cmaj/d3.wav', '../GrandPiano.cmaj/g2.wav', '../GrandPiano.cmaj/g3.wav', '../GrandPiano.cmaj/g6.wav', '../GrandPiano.cmaj/g4.wav', '../GrandPiano.cmaj/g5.wav']}\n"
     ]
    }
   ],
   "source": [
    "color = assign_color(85)\n",
    "possible_notes = assign_possible_notes(color)\n",
    "print(possible_notes)\n",
    "fundamentals = assign_fund(possible_notes, .6)\n",
    "fund = create_fund(fundamentals, 20)\n",
    "mel = assign_harm(possible_notes, .6, .6)\n",
    "melody = create_harm(mel, .6, .6, 20)\n",
    "create_score(fund, melody)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.color object at 0x1117cc630>\n",
      "g3\n"
     ]
    }
   ],
   "source": [
    "color = assign_color(85)\n",
    "print(color)\n",
    "possible_notes = assign_possible_notes(color)\n",
    "\n",
    "print(possible_notes['g'][1][-6:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/DJI_0097.MP4', '/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/DJI_0100.MP4', '/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/DJI_0101.MP4', '/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/DJI_0102.MP4', '/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/DJI_0103.MP4']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "vids = glob.glob(\"/Volumes/Workspace/wc/SeniorWork/BeldenFalls.9.12/drone/*.MP4\")\n",
    "\n",
    "print(vids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
